{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee1c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_strings_before_non_empty(lst):\n",
    "    result = []\n",
    "    skip_next = False\n",
    "    for element in lst:\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "        if element == '' and lst[lst.index(element) + 1] != '':\n",
    "            continue\n",
    "        result.append(element)\n",
    "        if element == '' and lst[lst.index(element) + 1] == '':\n",
    "            skip_next = True\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1dae4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_consecutive_empty_strings(lst):\n",
    "    prev_element = None\n",
    "    result = []\n",
    "    for element in lst:\n",
    "        if element == '' and prev_element == '':\n",
    "            continue\n",
    "        result.append(element)\n",
    "        prev_element = element\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22317564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_string(input_string):\n",
    "    \"\"\"\n",
    "    Replace the input string with an empty string if it contains any month name in either abbreviated or full form.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): Input string to check and replace.\n",
    "\n",
    "    Returns:\n",
    "        str: Output string with pattern replaced by an empty string, or the original input string if pattern not found.\n",
    "    \"\"\"\n",
    "    # Define the pattern to match any month name in either abbreviated or full form\n",
    "    pattern = r\"\\b(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{1,2},\\s*/\\s*\\d{1,2}:\\d{2}[APM\\s]+GMT\\b\"\n",
    "\n",
    "    # Use regular expression to find if the input string contains the pattern\n",
    "    if re.search(pattern, input_string, re.IGNORECASE):\n",
    "        # If pattern is found, replace the entire input string with an empty string\n",
    "        output_string = \"\"\n",
    "    else:\n",
    "        # If pattern is not found, keep the input string unchanged\n",
    "        output_string = input_string\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d039f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern2 =r\".*?[A-Z]{3}\\s\\d{1,2},\\s\\/\\s\\d{1,2}:\\d{2}(?:AM|PM)\\sGMT.*?(?=\\n\\n|$)\"\n",
    "def eliminate_special_characters(text):\n",
    "    # Regular expression to match solo numbers, copyright symbols, and the year that appears after the copyright symbol\n",
    "    pattern = r\"(?<!\\S)\\d+(?!\\S)|©\\s?\\d{2,4}\"    \n",
    "\n",
    "    # Replace matching patterns with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac84f23",
   "metadata": {},
   "source": [
    "document = docx2txt.process(\"data/word/19_Q1_2005.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca6838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data/PDF\\301_2002.pdf to data/word\\301_2002.docx\n",
      "Converted data/PDF\\305_2003.pdf to data/word\\305_2003.docx\n",
      "Converted data/PDF\\310_2004.pdf to data/word\\310_2004.docx\n",
      "Converted data/PDF\\311_2005.pdf to data/word\\311_2005.docx\n",
      "Converted data/PDF\\312_2006.pdf to data/word\\312_2006.docx\n",
      "Converted data/PDF\\320_2007.pdf to data/word\\320_2007.docx\n",
      "Converted data/PDF\\330_2008.pdf to data/word\\330_2008.docx\n",
      "Converted data/PDF\\340_2009.pdf to data/word\\340_2009.docx\n",
      "Converted data/PDF\\343_2010.pdf to data/word\\343_2010.docx\n",
      "Converted data/PDF\\432_2011.pdf to data/word\\432_2011.docx\n",
      "Converted data/PDF\\434_2013.pdf to data/word\\434_2013.docx\n",
      "Converted data/PDF\\459_2012.pdf to data/word\\459_2012.docx\n",
      "Converted data/PDF\\462_2014.pdf to data/word\\462_2014.docx\n",
      "Converted data/PDF\\463_2016.pdf to data/word\\463_2016.docx\n",
      "Converted data/PDF\\464_2017.pdf to data/word\\464_2017.docx\n",
      "Converted data/PDF\\465_2018.pdf to data/word\\465_2018.docx\n",
      "Converted data/PDF\\98_2019.pdf to data/word\\98_2019.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import fitz\n",
    "from docx import Document\n",
    "\n",
    "# Get all PDF files in the directory\n",
    "pdf_files = glob.glob(\"data/PDF/*.pdf\")\n",
    "\n",
    "# Specify the directory to save the DOCX files\n",
    "output_dir = \"data/word\"\n",
    "\n",
    "# Loop through each PDF file\n",
    "for pdf_file in pdf_files:\n",
    "    # Open the PDF file\n",
    "    pdf_doc = fitz.open(pdf_file)\n",
    "\n",
    "    # Create a new Word document\n",
    "    docx_file = os.path.join(output_dir, os.path.splitext(os.path.basename(pdf_file))[0] + \".docx\")\n",
    "    docx_doc = Document()\n",
    "\n",
    "    # Loop through each page in the PDF\n",
    "    for page in range(pdf_doc.page_count):\n",
    "        pdf_page = pdf_doc.load_page(page)\n",
    "        page_text = pdf_page.get_text(\"text\")\n",
    "\n",
    "        # Add the page text to the Word document\n",
    "        docx_doc.add_paragraph(page_text)\n",
    "\n",
    "    # Save the Word document\n",
    "    docx_doc.save(docx_file)\n",
    "    print(f\"Converted {pdf_file} to {docx_file}\")\n",
    "\n",
    "    # Close the PDF document\n",
    "    pdf_doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e02d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"CFO\",\"Analyst\", \"Director\", \"VP\", \"Operator\", \"Analytics\", \"DISCLAIMER\", \"Tristan\",'MD','Head','Chief Financial Officer',\\\n",
    "            'Credit Suisse','Deutsche Banc','US Bankcorp',' Morgan','Woody','Crest Securities','Alec Berman','Gartner','William Blair'\\\n",
    "           ,'Rob Henrikson','CIO','Saul Martinez','Smith Barney','Andrew Kligerman','Controller','Unknown Speaker','Joan Zief Goldman Sachs',\\\n",
    "           'President','Investor','COO',\"Manager\",\"Team Lead\",\"Product Manager\",\n",
    "    \"Marketing Specialist\",\n",
    "    \"Software Engineer\",\n",
    "    \"Data Scientist\",\n",
    "    \"Sales Manager\",\n",
    "    \"HR Manager\",\n",
    "    \"Business Analyst\",\n",
    "    \"Project Manager\",\n",
    "    \"Researcher\",\n",
    "    \"Product Owner\",\n",
    "    \"Operations Manager\",\n",
    "    \"UX Designer\",\n",
    "    \"UI Designer\",\n",
    "    \"Frontend Developer\",\n",
    "    \"Backend Developer\",\n",
    "    \"Database Administrator\",\n",
    "    \"System Administrator\",\n",
    "    \"Quality Assurance Analyst\",\n",
    "    \"Scrum Master\",\n",
    "    \"DevOps Engineer\",\n",
    "    \"Cloud Architect\",\n",
    "    \"Network Engineer\",\n",
    "    \"Security Analyst\",\n",
    "    \"IT Consultant\",\n",
    "    \"Financial Analyst\",\n",
    "    \"Supply Chain Manager\",\n",
    "    \"Operations Analyst\",\n",
    "    \"Customer Support Specialist\",\n",
    "    \"Graphic Designer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ab047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEO say for '19_Q1_2005.docx' saved to '19_Q1_2005_ceo_say.txt'\n",
      "CEO say for '301_2002.docx' saved to '301_2002_ceo_say.txt'\n",
      "CEO say for '305_2003.docx' saved to '305_2003_ceo_say.txt'\n",
      "CEO say for '310_2004.docx' saved to '310_2004_ceo_say.txt'\n",
      "CEO say for '311_2005.docx' saved to '311_2005_ceo_say.txt'\n",
      "CEO say for '312_2006.docx' saved to '312_2006_ceo_say.txt'\n",
      "CEO say for '320_2007.docx' saved to '320_2007_ceo_say.txt'\n",
      "CEO say for '330_2008.docx' saved to '330_2008_ceo_say.txt'\n",
      "CEO say for '340_2009.docx' saved to '340_2009_ceo_say.txt'\n",
      "CEO say for '343_2010.docx' saved to '343_2010_ceo_say.txt'\n",
      "CEO say for '432_2011.docx' saved to '432_2011_ceo_say.txt'\n",
      "CEO say for '434_2013.docx' saved to '434_2013_ceo_say.txt'\n",
      "CEO say for '459_2012.docx' saved to '459_2012_ceo_say.txt'\n",
      "CEO say for '462_2014.docx' saved to '462_2014_ceo_say.txt'\n",
      "CEO say for '463_2016.docx' saved to '463_2016_ceo_say.txt'\n",
      "CEO say for '464_2017.docx' saved to '464_2017_ceo_say.txt'\n",
      "CEO say for '465_2018.docx' saved to '465_2018_ceo_say.txt'\n",
      "CEO say for '98_2019.docx' saved to '98_2019_ceo_say.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx2txt\n",
    "\n",
    "# List of keywords for other names\n",
    "keywords = keywords\n",
    "\n",
    "# Directory containing the docx files\n",
    "docx_dir = 'data/word/'\n",
    "\n",
    "# Directory to save the output txt files\n",
    "output_dir = 'data/txt/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through all docx files in the directory\n",
    "for filename in os.listdir(docx_dir):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        # Open the Word document\n",
    "        docx_path = os.path.join(docx_dir, filename)\n",
    "        document = docx2txt.process(docx_path)\n",
    "\n",
    "        # Split the document into paragraphs\n",
    "        paragraphs = document.split(\"\\n\")\n",
    "\n",
    "        # Initialize a flag to track whether we are currently in the CEO's section\n",
    "        in_ceo_section = False\n",
    "\n",
    "        # Initialize a list to store the CEO say paragraphs\n",
    "        ceo_say_paragraphs = []\n",
    "\n",
    "        # Iterate through the paragraphs\n",
    "        for paragraph in paragraphs:\n",
    "            # Check if the paragraph contains the CEO's name\n",
    "            if \"CEO\" in paragraph:\n",
    "                # If the paragraph contains the CEO's name, set the flag to True\n",
    "                in_ceo_section = True\n",
    "                \n",
    "            # Check if the paragraph contains the CFO's, Analyst's, Director's, VP's, or Operator's name\n",
    "            elif any(keyword in paragraph for keyword in keywords):\n",
    "                # If the paragraph contains the CFO's, Analyst's, Director's, VP's, or Operator's name, set the flag to False\n",
    "                in_ceo_section = False\n",
    "            # If we are in the CEO's section, append the paragraph to the list of CEO say paragraphs\n",
    "            paragraph = paragraph.replace(\"Thomson Reuters. All rights reserved. Republication or redistribution of Thomson Reuters content, including by framing or similar\",'')\n",
    "            paragraph = paragraph.replace(\"means, is prohibited without the prior written consent of Thomson Reuters. 'Thomson Reuters' and the Thomson Reuters logo are\",'')\n",
    "            paragraph = paragraph.replace('registered trademarks of Thomson Reuters and its affiliated companies.','')\n",
    "            paragraph = paragraph.replace('THOMSON REUTERS | Contact Us','')\n",
    "            paragraph = eliminate_special_characters(paragraph)\n",
    "            paragraph = replace_string(paragraph)\n",
    "            if in_ceo_section:\n",
    "                ceo_say_paragraphs.append(paragraph)        \n",
    "        ceo_say_paragraphs = remove_consecutive_empty_strings(ceo_say_paragraphs)\n",
    "        ceo_say_paragraphs = remove_empty_strings_before_non_empty(ceo_say_paragraphs)       \n",
    "        #ceo_say_paragraphs = remove_consecutive_empty_strings(ceo_say_paragraphs)\n",
    "        # Join the CEO say paragraphs into a single string\n",
    "        ceo_say = \"\\n\".join(ceo_say_paragraphs)\n",
    "\n",
    "        # Save the CEO say to a txt file in the output directory with the same name as the input docx file\n",
    "        output_file = os.path.splitext(filename)[0] + \"_ceo_say.txt\"\n",
    "        output_path = os.path.join(output_dir, output_file)\n",
    "        with open(output_path, \"w\") as file:\n",
    "            file.write(ceo_say)\n",
    "        print(f\"CEO say for '{filename}' saved to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce5543",
   "metadata": {},
   "source": [
    "# Rough Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c776239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String:  This is a sample string 12345 with numbers 123 and spaces   123   around\n",
      "Output String:  This is a sample string  with numbers 123 and spaces   123   around\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the input string\n",
    "input_string = \"This is a sample string 12345 with numbers 123 and spaces   123   around\"\n",
    "\n",
    "# Define the pattern to match the string with any number value\n",
    "pattern = r\"\\b(\\d+)\\b\"\n",
    "\n",
    "# Define the function to replace the matched string with empty string if surrounded by 3 spaces or more\n",
    "def replace_string(match):\n",
    "    if len(match.group(0)) > 3:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return match.group(0)\n",
    "\n",
    "# Use regular expression to find and replace the string in the input string\n",
    "output_string = re.sub(pattern, replace_string, input_string)\n",
    "\n",
    "# Print the output string\n",
    "print(\"Input String: \", input_string)\n",
    "print(\"Output String: \", output_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "\n",
    "#def eliminate_special_characters(text):\n",
    "#    # Regular expression to match solo numbers, copyright symbols, and the year that appears after the copyright symbol\n",
    "#    pattern = r\"(?<!\\S)\\d+(?!\\S)|©\\s?\\d{2,4}\"\n",
    "\n",
    "#    # Replace matching patterns with an empty string\n",
    "#    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "#    return cleaned_text\n",
    "\n",
    "#text = \"Hello, this is a test text. © 2023 The number 123 should be removed. 42 But 4.5 and 123abc should stay.\"\n",
    "\n",
    "#cleaned_text = eliminate_special_characters(text)\n",
    "#print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661aab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String:  MAY 02,  / 1:00PM GMT, Q1  CF Industries Holdings Inc Earnings Call\n",
      "Output String:  , Q1  CF Industries Holdings Inc Earnings Call\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the input string\n",
    "input_string = \"MAY 02,  / 1:00PM GMT, Q1  CF Industries Holdings Inc Earnings Call\"\n",
    "\n",
    "# Define the pattern to match the given format\n",
    "pattern = r\"\\b\\w{3} \\d{2},\\s*/\\s*\\d{1,2}:\\d{2}[APM\\s]+GMT\\b\"\n",
    "\n",
    "# Use regular expression to find and replace the string in the input string\n",
    "output_string = re.sub(pattern, \"\", input_string)\n",
    "\n",
    "# Print the output string\n",
    "print(\"Input String: \", input_string)\n",
    "print(\"Output String: \", output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779580bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f008d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String:  MAY 02,  / 1:00PM GMT, Q1  CF Industries Holdings Inc Earnings Call\n",
      "Output String:  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_string(input_string):\n",
    "    \"\"\"\n",
    "    Replace the input string with an empty string if it contains the pattern 'MAY 02,  / 1:00PM GMT,'.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): Input string to check and replace.\n",
    "\n",
    "    Returns:\n",
    "        str: Output string with pattern replaced by an empty string, or the original input string if pattern not found.\n",
    "    \"\"\"\n",
    "    # Define the pattern to match the given format\n",
    "    pattern = r\"\\b\\w{3} \\d{2},\\s*/\\s*\\d{1,2}:\\d{2}[APM\\s]+GMT\\b\"\n",
    "\n",
    "    # Use regular expression to find if the input string contains the pattern\n",
    "    if re.search(pattern, input_string):\n",
    "        # If pattern is found, replace the entire input string with an empty string\n",
    "        output_string = \"\"\n",
    "    else:\n",
    "        # If pattern is not found, keep the input string unchanged\n",
    "        output_string = input_string\n",
    "\n",
    "    return output_string\n",
    "\n",
    "# Test the function with an example input string\n",
    "input_string = \"MAY 02,  / 1:00PM GMT, Q1  CF Industries Holdings Inc Earnings Call\"\n",
    "output_string = replace_string(input_string)\n",
    "print(\"Input String: \", input_string)\n",
    "print(\"Output String: \", output_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001c4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_consecutive_empty_paragraphs(paragraphs):\n",
    "    # Create a new list to store the non-empty paragraphs\n",
    "    new_paragraphs = []\n",
    "\n",
    "    # Keep track of whether the previous paragraph was empty\n",
    "    prev_empty = False\n",
    "\n",
    "    # Loop through each paragraph\n",
    "    for paragraph in paragraphs:\n",
    "        # Check if the paragraph is empty\n",
    "        if paragraph.strip() == '':\n",
    "            # If the previous paragraph was also empty, skip this one\n",
    "            if prev_empty:\n",
    "                continue\n",
    "            # Otherwise, mark this paragraph as empty and add it to the new list\n",
    "            prev_empty = True\n",
    "            new_paragraphs.append(paragraph)\n",
    "        else:\n",
    "            # If the paragraph is not empty, add it to the new list and mark the previous paragraph as not empty\n",
    "            prev_empty = False\n",
    "            new_paragraphs.append(paragraph)\n",
    "\n",
    "    # Join the new list of paragraphs back into a string\n",
    "    new_text = '\\n\\n'.join(new_paragraphs)\n",
    "\n",
    "    # Look for consecutive empty paragraphs\n",
    "    while '\\n\\n\\n' in new_text:\n",
    "        new_text = new_text.replace('\\n\\n\\n', '\\n\\n')\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4c33f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15328\\4212405313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mceo_say_paragraphs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mceo_say_paragraphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_consecutive_empty_strings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mceo_say_paragraphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mceo_say_paragraphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_empty_strings_before_non_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mceo_say_paragraphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Join the CEO say paragraphs into a single string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15328\\2374731139.py\u001b[0m in \u001b[0;36mremove_empty_strings_before_non_empty\u001b[1;34m(lst)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mskip_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0melement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "\n",
    "# Open the Word document\n",
    "document = docx2txt.process(\"data/word/98_2019.docx\")\n",
    "\n",
    "# Split the document into paragraphs\n",
    "paragraphs = document.split(\"\\n\")\n",
    "\n",
    "# Initialize a flag to track whether we are currently in the CEO's section\n",
    "in_ceo_section = False\n",
    "\n",
    "# Initialize a list to store the CEO say paragraphs\n",
    "ceo_say_paragraphs = []\n",
    "\n",
    "# Iterate through the paragraphs\n",
    "for paragraph in paragraphs:\n",
    "            # Check if the paragraph contains the CEO's name\n",
    "    if \"CEO\" in paragraph:\n",
    "                # If the paragraph contains the CEO's name, set the flag to True\n",
    "        in_ceo_section = True\n",
    "                \n",
    "            # Check if the paragraph contains the CFO's, Analyst's, Director's, VP's, or Operator's name\n",
    "    elif any(keyword in paragraph for keyword in keywords):\n",
    "                # If the paragraph contains the CFO's, Analyst's, Director's, VP's, or Operator's name, set the flag to False\n",
    "        in_ceo_section = False\n",
    "            # If we are in the CEO's section, append the paragraph to the list of CEO say paragraphs\n",
    "    paragraph = paragraph.replace(\"Thomson Reuters. All rights reserved. Republication or redistribution of Thomson Reuters content, including by framing or similar\",'')\n",
    "    paragraph = paragraph.replace(\"means, is prohibited without the prior written consent of Thomson Reuters. 'Thomson Reuters' and the Thomson Reuters logo are\",'')\n",
    "    paragraph = paragraph.replace('registered trademarks of Thomson Reuters and its affiliated companies.','')\n",
    "    paragraph = paragraph.replace('THOMSON REUTERS | Contact Us','')\n",
    "    paragraph = eliminate_special_characters(paragraph)\n",
    "    paragraph = replace_string(paragraph)\n",
    "    if in_ceo_section:\n",
    "        ceo_say_paragraphs.append(paragraph)        \n",
    "    ceo_say_paragraphs = remove_consecutive_empty_strings(ceo_say_paragraphs)\n",
    "    ceo_say_paragraphs = remove_empty_strings_before_non_empty(ceo_say_paragraphs)\n",
    "   \n",
    "    # Join the CEO say paragraphs into a single string\n",
    "    ceo_say = \"\\n\".join(ceo_say_paragraphs)\n",
    "\n",
    "# Join the CEO say paragraphs into a single string\n",
    "ceo_say = \"\\n\".join(ceo_say_paragraphs)\n",
    "print(ceo_say_paragraphs)\n",
    "\n",
    "# Save the CEO say to a txt file\n",
    "with open(\"ceo_say.txt\", \"w\") as file:\n",
    "    file.write(ceo_say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['assad', ' ', '     ', 'care']\n",
    "\n",
    "# Remove empty strings ('') from the list\n",
    "my_list = [item for item in my_list if item.strip() != '']\n",
    "\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f161c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
